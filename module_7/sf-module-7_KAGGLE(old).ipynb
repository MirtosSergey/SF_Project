{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Проект выполнил: *Светлаков Сергей, студент SkillFactory группы DSPR-38 (DSPR-1)*\n# Проект: *Ford VS Ferrari*\n# Дата начала работы: *04.05.2021*\n# Дата сдачи: *06.05.2021*","metadata":{}},{"cell_type":"markdown","source":"## Цель работы: создать и обучить нейронную сеть по типу CNN (сверточная нейронная сеть) для решения задачи классификации изображений по классам. В качестве изображений выступают фото машин, а классов - модели автомобилей. Метрика: точность предсказаний. Данная работа выполнялась на основе имеющегося Base-Line решения на платформе SkillFactory.","metadata":{}},{"cell_type":"markdown","source":"***\n***В данном notebook представлена финальная версия программы с промежуточными пояснениями к прошлым версиям.***\n***","metadata":{}},{"cell_type":"markdown","source":"***\n***Для ускорения расчетов используется видео-карта, представленная площадкой Kaggle.***\n***","metadata":{}},{"cell_type":"code","source":"#Информация по видео-карте\n!nvidia-smi","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Подключение библиотек","metadata":{}},{"cell_type":"code","source":"#Подключение библиотек\n#Для работы с данными\nimport numpy as np\nimport pandas as pd\n#Для визуализации\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#Для работы с файлами\nimport pickle\nimport zipfile\nimport csv\nimport sys\nimport os\n#Для работы с изображениями\nimport PIL\nfrom PIL import ImageOps, ImageFilter\n#Для разбиение выборок\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n#Для работы с ML-CV\nimport tensorflow as tf\nimport tensorflow.keras.layers as L                                    #Типы слоев\nimport tensorflow.keras.models as M                                    #Типы моделей\nimport tensorflow.keras.optimizers as O                                #Типы решателей\nfrom tensorflow.keras.regularizers import l2                           #Регуляризация для Dense\nfrom tensorflow.keras.preprocessing import image                       \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator    #Генератор (для test)\nfrom tensorflow.keras.callbacks import Callback,\\\n                                       EarlyStopping,\\\n                                       LearningRateScheduler,\\\n                                       ReduceLROnPlateau,\\\n                                       ModelCheckpoint","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n***Далее устанавливаются и подключаются еще несколько библиотек для fine-tuning и augmentation.***\n***","metadata":{}},{"cell_type":"code","source":"#Изменение размера и оформления графиков\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n%config InlineBackend.figure_format = 'svg' \n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Версии используемых библиотек:')\nprint('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\nprint('Tensorflow   :', tf.__version__)\nprint('Keras        :', tf.keras.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Настройки для CV-моделей","metadata":{}},{"cell_type":"markdown","source":"***\n***Заранее вынесем настройки нейронной сети, перед ее созданием и обучением.***\n***Несколько слов о том, как выбирались настройки: сначала были взяты параметры с Base-Line решения SkillFactory, затем при обучении и дообучении модели параметры выбирались так, чтобы получить максимальную точность accuracy, при условии предотвращения возникновения ошибки OOM: out of memory - дефицит машинной памяти на используемом вычислительном ресурсе - видеокарте. Исходный BATCH_SIZE (размер батча) был равен 64 и для fine-tuning выбрана модель EfficientNetB6, но уже при разморозке сети на 50% появлялась ошибка OOM. В итоге была выбрана новая модель для transfer learning - EfficientNetB5, а размер батча снижен до 32, чтобы предотвратить OOM. Количество эпох изначально было равно 5, но было повышено до 15. После предварительных расчетов было выявлено, что количество эпох можно снизить до 8-10, так как дальнейшее обучение модели приводит к снижению метрики качества на валидационной выборке.***\n***","metadata":{}},{"cell_type":"code","source":"#Параметры сети\nRANDOM_SEED    = 42   #Воспроизведение результатов\nEPOCHS         = 10   #Количество эпох на обучение\nBATCH_SIZE     = 16   #BATCH, подаваемый в сеть\nLR             = 1e-3 #Скорость обучения\nVAL_SPLIT      = 0.15 #Размер валидационной выборки в сравнении с общей\n#Параметры изображения\nCLASS_NUM      = 10   #Количество классов в задачей\nIMG_SIZE       = 224  #Размер изображения, подаваемого в сеть\nIMG_CHANNELS   = 3    #Количество каналов: красный, зеленый, синий\ninput_shape    = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n#Пути хранения файлов\nDATA_PATH = '../input/sf-dl-car-classification/'  #Директория, содержащая данные\nPATH = \"../working/car/\"                          #Директория, содержащая модели","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. EDA","metadata":{}},{"cell_type":"markdown","source":"***\n***Чтобы не перегружать хранилище (max 20GB) каждый раз перед повторным запуском очищаем директорию working.***\n***","metadata":{}},{"cell_type":"code","source":"#Очистка папки перед началом работы\n!rm -r /kaggle/working/*","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Чтение обучающей выборки\ndf_train = pd.read_csv(DATA_PATH+\"train.csv\")\n#Чтение для submit на Kaggle\nsample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\n#Осмотр данных\ndf_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n***Видно, что DataFrame состоит из ссылки на картинку и какому классу принадлежит данная прецендент (картинка).***\n***","metadata":{}},{"cell_type":"code","source":"#Информация о DF\ndf_train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n***В DataFrame нет пропущенных или лишних значений.***\n***","metadata":{}},{"cell_type":"code","source":"#Распределение прецендентов по классам\ndf_train['Category'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n***Присутствует небольшой дисбаланс классов, но на первоначальном этапе попробуем не применять OverSampler или UnderSampler.***\n***","metadata":{}},{"cell_type":"code","source":"#Распаковка картинок - извлечение в PATH\nfor data_zip in ['train.zip', 'test.zip']:\n    with zipfile.ZipFile(DATA_PATH+data_zip,\"r\") as z:\n        z.extractall(PATH)\n#Название извлеченных папок \nprint('Название извлеченных папок: {}'.format(os.listdir(PATH)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Извлечение случайной картинки\nimage = PIL.Image.open(PATH+'/train/0/100380.jpg')\n#построение графика\nimgplot = plt.imshow(image)\n#Отображение\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n***Каждый прецендент содержит фото автомобиля. Посмотрим на еще несколько картинок, чтобы понять: все ли автомобили сфотографированы с одного ракурса?***\n***","metadata":{}},{"cell_type":"code","source":"#Перебор\nfor name in df_train['Id'].iloc[:9].values:\n    #Извлечение случайной картинки\n    image = PIL.Image.open(PATH+'/train/0/'+name)\n    #построение графика\n    imgplot = plt.imshow(image)\n    #Отображение\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n***Ракурс может быть абсолютно случайным. Может быть случайным и размер фотографии. Также где-то присутствует случайным шум, разная контрасность, цветовая гамма и так далее. Если не учесть все эти факторы - это может привести к обучению некачественной модели. Для улучшения качества предсказаний применим аугментацию данных - сгенерируем на основе имеющихся изображений случайные новые, созданные на основе исходных, путем добавления различных эффектов, разворота/поворота/сдвига и так далее. Стоит упомянуть, что изображение цветное, значит каналов будет 3: red, green, blue.***\n***","metadata":{}},{"cell_type":"markdown","source":"# 4. Аугментация данных","metadata":{}},{"cell_type":"markdown","source":"***\n***Для аугментации данных используем библиотеку albumentations. А обертку для TensorFlow скачаем по ссылке от SkillFactore.***\n***","metadata":{}},{"cell_type":"code","source":"#Используем готовую \"продвинутую\" библиотеку для аугментации данных\n#Ссылка SkillFactory\n!pip install git+https://github.com/mjkvaak/ImageDataAugmentor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Импорт библиотек для аугментации\nimport albumentations as alb\nfrom ImageDataAugmentor.image_data_augmentor import *","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n***По ссылке ниже изучим какие можно добавить эффекты на изображения и поэкспериментируем, как добавление/удаление их сказывается на качестве модели при ее обучении.***\n***","metadata":{}},{"cell_type":"code","source":"#Ссылка - https://albumentations.ai/docs/api_reference/augmentations/transforms/\n#         #albumentations.augmentations.transforms.GaussianBlur\np = 0.5 #Вероятность изменить изображение\n#Создание аугментатора\naugment = alb.Compose([\n    #Замена каналов в RGB палитре\n    alb.ChannelShuffle(p=p),\n    #   #Увеличение изображение RGB по статье Крижевского\n    #   alb.FancyPCA(p=p),\n    #Размытие изображения\n    alb.GaussianBlur(p=p),\n    #Добавление шума\n    alb.GaussNoise(p=p),\n    #   #Добавление шума\n    #   alb.GlassBlur(p=p),\n    #Поворот вокруг вертикальной оси\n    alb.HorizontalFlip(p=p),\n    #Изменение оттенка и насыщенности\n    alb.HueSaturationValue(p=p),\n    #   #Размытие в движение\n    #   alb.MotionBlur(p=p),\n    #Изменение яркости\n    alb.RandomBrightness(p=p,limit=(0.2,0.4)),\n    #Изменение контраста\n    alb.RandomContrast(p=p,limit=(0.1,0.3)),\n    #   #Имитирование вспышки\n    #   alb.RandomSunFlare(p=p),\n    #Сдвиг в RGB палитре\n    alb.RGBShift(p=p),\n    #Вращение изображения\n    alb.ShiftScaleRotate(shift_limit=0.0625,      #Коэффициент изменения сдвига\n                         scale_limit=(0.1,0.2),   #Коэффициент изменение масштаба\n                         interpolation=1,         #Флаг для вида интерполяции (линейная)\n                         border_mode=4,           #Флаг для экстраполяцц (отражение)\n                         rotate_limit=20,         #Угол поворота\n                         p=0.7),                  #Вероятность\n    #Изменение размера на заданный\n    alb.Resize(IMG_SIZE, IMG_SIZE)\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n***Опытным путем было установлено, что попытка смоделировать солнечную вспышку или размытость фотографии из-за движения фотографирующего не привела ни к чему хорошему.***\n***","metadata":{}},{"cell_type":"code","source":"#Генератор для обучающей и валидационной выборок\ntrain_gen = ImageDataAugmentor(rescale=1.0/255,                     #Масштабирование\n                               augment=augment,                     #Аугментатор\n                               seed=RANDOM_SEED,                    #Для воспроизведения\n                               validation_split=VAL_SPLIT)          #Размер выборки\n#Генератор для тестовой выборки\ntest_gen = ImageDataGenerator(rescale=1.0/255)\n#Создание обучающей выборки\ntrain_datagen = train_gen.\\\n            flow_from_directory(PATH+'train/',                      #Путь\n                                class_mode='categorical',           #Тип данных\n                                batch_size=BATCH_SIZE,              #Размер BATCH'а\n                                target_size=(IMG_SIZE, IMG_SIZE),   #Размер матрицы\n                                shuffle=True,                       #Перемешиваем заранее\n                                subset='training')                  #Название\n#Создание валидационной выборки\ntest_datagen = train_gen.\\\n            flow_from_directory(PATH+'train/',                      #Путь\n                                class_mode='categorical',           #Тип данных\n                                batch_size=BATCH_SIZE,              #Размер BATCH'а\n                                target_size=(IMG_SIZE, IMG_SIZE),   #Размер матрицы\n                                shuffle=True,                       #Перемешиваем заранее\n                                subset='validation')                #Название\n#Создание тестовой выборки\ntest_sub_generator = test_gen.\\\n            flow_from_dataframe(dataframe=sample_submission,\n                                x_col=\"Id\",\n                                y_col=None,\n                                directory=PATH+'test_upload/',\n                                class_mode=None,\n                                batch_size=BATCH_SIZE,\n                                shuffle=False,\n                                target_size=(IMG_SIZE, IMG_SIZE),\n                                seed=RANDOM_SEED)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n***Создали 2 генератора и на их основе сгенерировали 3 группы изображений: обучающая и валидационная выборки (train_gen) и тестовая выборка (test_gen).***\n***","metadata":{}},{"cell_type":"code","source":"#Импорт библиотеки для просмотра изображений\nfrom skimage import io\n\n#Функция для просмотра изображений\ndef imshow(image_RGB):\n    io.imshow(image_RGB)\n    io.show()\n    pass\n\n#Создание массива\nx,y = train_datagen.next()\n#Размер картинки\nplt.figure(figsize=(12,12))\n#Перебор\nfor i in range(0,9):\n    #Извлечении картинки\n    image = x[i]\n    #Создание места для графика\n    plt.subplot(3,3, i+1)\n    #Добавление картинки\n    plt.imshow(image)\n#Вывод\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n***Видно, что аугментация прошла успешна. Видны примеры измения контрасности, освещения и т.д.***\n***","metadata":{}},{"cell_type":"markdown","source":"# 5. Извлечение 'головы' и создание модели - SOTA","metadata":{}},{"cell_type":"markdown","source":"***\n***Для улучшения качества предсказаний в достаточно ограниченном количестве ресурсов, как временных, так и вычислительных, воспользуемся готовой обученной моделью и постепенно переобучим готовую модель под данную задачу. Данная операция называется fine-tuning, если обучение частичное и transfer learning, если переобучается вся 'голова'.***\n***","metadata":{}},{"cell_type":"code","source":"#https://paperswithcode.com/sota/image-classification-on-imagenet\n#Установка библиотеки\n!pip install -q efficientnet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Импорт библиотек для аугментации\nimport efficientnet.tfkeras as efn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n***Изначально в качестве 'головы' модели выбрана модель EfficientNetB6, но из-за большого количества весов в ней (60 млн.) сеть не поддается обучению из-за ограничения по количеству используемой памяти. Поэтому модель была заменена на EfficientNetB5. Также тестировалась модель Xception, но она показывала результат на 1-2% хуже.***\n***","metadata":{}},{"cell_type":"code","source":"#Базовая модель\nbase_model = efn.EfficientNetB5(weights='imagenet',        #Обученная на imagenet\n                                include_top=False,         #Включать ли верхнюю часть сети\n                                input_shape=input_shape)   #Размер матрицы","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n***Далее необходимо сконструировать архитектуру сети. Ниже представлена финальная версия, которая дала наилучший результат. Также в качестве комментариев под кодом приведены различные ранние версии и причины, по которым они не используются.***\n***","metadata":{}},{"cell_type":"code","source":"#Создание модели для обучения\nmodel = M.Sequential()\n#Добавление слоев\nmodel.add(base_model)                                #Слой 1 - базовая модель B6\nmodel.add(L.GlobalAveragePooling2D())                #Слой 2 - пулинг слой\nmodel.add(L.Dense(256,                               #Слой 3 - обычная сеть\n                  activation='relu',\n                  bias_regularizer=l2(1e-4),\n                  activity_regularizer=l2(1e-5)))\nmodel.add(L.BatchNormalization())                    #Слой 4 - Batch-нормализация\nmodel.add(L.Dropout(0.25))                           #Слой 5 - Drop нейронов\nmodel.add(L.Dense(CLASS_NUM,                         #Слой 6 - Выходной слой\n                  activation='softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n***В финальной версии для ускорения сходимости применяется Батч-нормализация. Также для предотвращения переобучения применяется регуляризация к Dense слою. Дополнительно для предотвращения переобучения применяется DropOut слой.***\n***","metadata":{}},{"cell_type":"code","source":"#Вариант 1: Dense cлой 256 + relu (итоговый)\n#Вариант 2: Dense cлой 512 + relu\n#Вариант 3: Dense cлой 256 + elu\n#Вариант 4: Dense cлой 256x256 + relu","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n***Вариант 2 практически не дал никакой разницы, лишь увеличил время обучения. Вариант 3 улучшил качество на валидационной выборке, но ухудшил на Kaggle (скорее всего переобучение). Вариант 4 не также, как и вариант 3 улучшил качество, но совсем незначительно. Для вариант 4 после дополнительного Dense слоя применяется батч-нормализация и drop-out слой.***\n***","metadata":{}},{"cell_type":"markdown","source":"# 6. Обучение модели (transfer-learning+finetuning)","metadata":{}},{"cell_type":"markdown","source":"***\n***Для улучшения качества обучения добавим функции, которые помогают фиксировать лучший результат и изменять темп обучения в автоматическом режиме. Была попытка использовать LearningRateScheduler, но она не привела к значимым результатам.***\n***","metadata":{}},{"cell_type":"code","source":"#Сохранение прогресса обучения\n#Сохранение модели\ncheckpoint = ModelCheckpoint('best_model.hdf5', \n                             monitor = ['val_accuracy'],    #Метрика контроля\n                             verbose = 1,                   #Вывод информации\n                             mode = 'max')                  #Max metrics\n#Ранняя оставка, когда метрика не растет\nearlystop = EarlyStopping(monitor = 'val_accuracy',         #Метрика контроля\n                          patience = 5,                     #Кол-во эпох без роста\n                          restore_best_weights = True)      #Если провал, то возврат?\n#Уменьшение темпа обучения, когда метрика падает\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',           #Метрика контроля\n                              factor=0.2,                   #Во сколько раз снижается\n                              patience=3,                   #Кол-во эпох без улучшения\n                              min_lr=0.000001,              #Минимальное значение\n                              verbose=1,                    #Вывод информации\n                              mode='auto')                  #Какая величина контролируется\n#Полный список callbacks\ncallbacks_list = [checkpoint, earlystop, reduce_lr]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n***Так как в данном notebook повторяется из раза в раз обучение одной и той же модели, то была специальна написана функция для сокращения общего количества кода.***\n***","metadata":{}},{"cell_type":"code","source":"#Функции для обучения моделей\ndef get_plot_history(history):\n    '''\n    Построение графиков: функция потерь и метрика качества на выборках в зав-ти от эпох.\n    Вход:\n    * history - модель.\n    Выход:\n    * None.\n    '''\n    #Вывод метрики\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    #Вывод функции потерь\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    #Количество эпох\n    epochs = range(len(acc))\n    #Построение графика - метрика качества\n    plt.plot(epochs, acc, 'b', label='Training acc')\n    plt.plot(epochs, val_acc, 'r', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n    #Построение графика - функция потерь\n    plt.figure()\n    plt.plot(epochs, loss, 'b', label='Training loss')\n    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n    #Показ графиков\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model,base_model,size,lr,name,key_fit,train_datagen,test_datagen,EPOCHS):\n    '''\n    Функция для обучения модели с размороженной головой.\n    Вход:\n    * model - модель для обучения;\n    * base_model - голова модели;\n    * size - размер заморозки головы модели;\n    * lr - темп обучения;\n    * name - индекс в названии файла модели;\n    * train_datagen - сгенерированная обучающая выборка;\n    * test_datagen - сгенерированная валидационная выборка;\n    * EPOCHS - число эпох.\n    Выход:\n    * model, base_model.\n    '''\n    #Обучение модели\n    base_model.trainable = True\n    #Количество слоев\n    len_lay = len(base_model.layers)\n    #Количество слоев для заморозки\n    fine_tune_lay = int(len_lay * size)\n    #Заморозка\n    for layer in base_model.layers[:fine_tune_lay]:\n        layer.trainable =  False\n    #Компиляция задачи: модель, метрика и функция потерь\n    model.compile(loss=\"categorical_crossentropy\", \n                  optimizer=O.Adam(lr=lr), \n                  metrics=[\"accuracy\"])\n    #Скелет модели\n    model.summary()\n    #Обучение\n    if key_fit == 1:\n        history = model.fit(\n            train_datagen,\n            steps_per_epoch = len(train_datagen),\n            validation_data = test_datagen, \n            validation_steps = len(test_datagen),\n            epochs = EPOCHS,\n            callbacks = callbacks_list)\n        #Сохранение\n        model.save('../working/best_model_'+name+'.hdf5')\n        #Метрика качества\n        scores = model.evaluate(test_datagen, verbose=1)\n        print(\"Accuracy: %.3f%%\" % (scores[1]*100))\n        #Графики\n        get_plot_history(history)\n    else:\n        model.load_weights('../working/best_model_'+name+'.hdf5')\n    return model, base_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n***Если модель обучается, то 1; если читается готовая, то 0.***\n***","metadata":{}},{"cell_type":"code","source":"#Обучать (1) или читать модель (0)\nkey_fit = 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n***Убедимся, что работает именно GPU.***\n***","metadata":{}},{"cell_type":"code","source":"#Список используемых устройств\ntf.config.list_physical_devices('GPU')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n***Далее постепенно размораживаем готовую модель и дообучаем всю модель на 10 эпохах. При размораживании 'головы' уменьшаем темп обучения в 5-10 раз. Количество эпох подобрано опытным путем. Чтобы не получать снижение качества на валидации необходимо выбирать количество эпох от 8 до 10. Были попытки увеличивать темп обучения после его снижения (чтобы выскочить из предполагаемого локального оптимума) и в дальнейшем снижать его, но это также не дало значимых результатов.***\n***","metadata":{}},{"cell_type":"code","source":"#Исходная модель: голова заморожена, обучаем хвост\nmodel, base_model = train_model(model,base_model,1.00,LR*1.00,'0',\n                                key_fit,train_datagen,test_datagen,EPOCHS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Первая модель: голова на 50% разморожена, обучаем хвост и оставшуюся часть головы\nmodel, base_model = train_model(model,base_model,0.50,LR*0.10,'1',\n                                key_fit,train_datagen,test_datagen,EPOCHS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Вторая модель: голова на 75% разморожена, обучаем хвост и оставшуюся часть головы\nmodel, base_model = train_model(model,base_model,0.25,LR*0.02,'2',\n                                key_fit,train_datagen,test_datagen,EPOCHS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n***На следующем этапе количество эпох сокращено до 5, так как при большем количестве начинает падать метрика на валидационной выборке - переобучение.***\n***","metadata":{}},{"cell_type":"code","source":"#Третья модель: голова на 100% разморожена, обучаем хвост и оставшуюся часть головы\nmodel, base_model = train_model(model,base_model,0.00,LR*0.01,'3',\n                                key_fit,train_datagen,test_datagen,EPOCHS=5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n***Финальный график зависимости функции потерь и метрики приведен в конце notebook.***\n***","metadata":{}},{"cell_type":"markdown","source":"# 7. Изменение IMAGE_SIZE, BATCH и AUGMENTATION","metadata":{}},{"cell_type":"markdown","source":"***\n***Для повышения точности предсказания уменьшаем влияние аугментации и увеличиваем размер картинки, при этом снижаем размер батча, чтобы хватило памяти.***\n***","metadata":{}},{"cell_type":"code","source":"#Изменение глобальных настроек\nEPOCHS         = 8\nBATCH_SIZE     = 4\nLR             = 1e-5\nIMG_SIZE       = 512\nIMG_CHANNELS   = 3\ninput_shape    = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n***Количество эпох подобрано опытным путем. Оптимальным вариантом является 4-8.***\n***","metadata":{}},{"cell_type":"code","source":"p = 0.5 #Вероятность изменить изображение\n#Создание аугментатора\naugment = alb.Compose([\n    #Поворот вокруг вертикальной оси\n    alb.HorizontalFlip(p=p),\n    #Вращение изображения\n    alb.ShiftScaleRotate(shift_limit=0.0625,      #Коэффициент изменения сдвига\n                         scale_limit=(0.1,0.2),   #Коэффициент изменение масштаба\n                         interpolation=1,         #Флаг для вида интерполяции (линейная)\n                         border_mode=4,           #Флаг для экстраполяцц (отражение)\n                         rotate_limit=20,         #Угол поворота\n                         p=0.7),                  #Вероятность\n    #Изменение размера на заданный\n    alb.Resize(IMG_SIZE, IMG_SIZE)\n])\n#Генерируем данные заного\n#Генератор для обучающей и валидационной выборок\ntrain_gen = ImageDataAugmentor(rescale=1.0/255,                     #Масштабирование\n                               augment=augment,                     #Аугментатор\n                               seed=RANDOM_SEED,                    #Для воспроизведения\n                               validation_split=VAL_SPLIT)          #Размер выборки\n#Генератор для тестовой выборки\ntest_gen = ImageDataGenerator(rescale=1.0/255)\n#Создание обучающей выборки\ntrain_datagen = train_gen.\\\n            flow_from_directory(PATH+'train/',                      #Путь\n                                class_mode='categorical',           #Тип данных\n                                batch_size=BATCH_SIZE,              #Размер BATCH'а\n                                target_size=(IMG_SIZE, IMG_SIZE),   #Размер матрицы\n                                shuffle=True,                       #Перемешиваем заранее\n                                subset='training')                  #Название\n#Создание валидационной выборки\ntest_datagen = train_gen.\\\n            flow_from_directory(PATH+'train/',                      #Путь\n                                class_mode='categorical',           #Тип данных\n                                batch_size=BATCH_SIZE,              #Размер BATCH'а\n                                target_size=(IMG_SIZE, IMG_SIZE),   #Размер матрицы\n                                shuffle=True,                       #Перемешиваем заранее\n                                subset='validation')                #Название\n#Создание тестовой выборки\ntest_sub_generator = test_gen.\\\n            flow_from_dataframe(dataframe=sample_submission,\n                                x_col=\"Id\",\n                                y_col=None,\n                                directory=PATH+'test_upload/',\n                                class_mode=None,\n                                batch_size=BATCH_SIZE,\n                                shuffle=False,\n                                target_size=(IMG_SIZE, IMG_SIZE),\n                                seed=RANDOM_SEED)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Создаем голову заново для нового размера картинок\nbase_model = efn.EfficientNetB5(weights='imagenet',        #Обученная на imagenet\n                                include_top=False,         #Включать ли верхнюю часть сети\n                                input_shape=input_shape)   #Размер матрицы\n#Загружаем веса с прошлой итерации\nmodel.load_weights('best_model_3.hdf5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Четвертая модель: все разморожено и изменения в BATCH и AUGMENTATION\nmodel, base_model = train_model(model,base_model,0.00,LR,'4',\n                                key_fit,train_datagen,test_datagen,EPOCHS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n***В результате качество на валидационной выборке было повышено на ~2%. Можно считать данную модель оптимальную из всех полученных ранее.***\n***","metadata":{}},{"cell_type":"markdown","source":"# 8. Kaggle v.1","metadata":{}},{"cell_type":"code","source":"def to_Kaggle(model):\n    #Код взят с SkillFactory\n    test_sub_generator.reset()\n    predictions = model.predict_generator(test_sub_generator, steps=len(test_sub_generator), verbose=1) \n    predictions = np.argmax(predictions, axis=-1)\n    label_map = (train_datagen.class_indices)\n    label_map = dict((v,k) for k,v in label_map.items())\n    predictions = [label_map[k] for k in predictions]\n    filenames_with_dir=test_sub_generator.filenames\n    submission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\n    submission['Id'] = submission['Id'].replace('test_upload/','')\n    submission.to_csv('submission.csv', index=False)\n    print('Save submit')\n    pass","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n***Результат на Kaggle приведен в конце notebook.***\n***","metadata":{}},{"cell_type":"code","source":"#submit на Kaggle\nto_Kaggle(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 9.TTA","metadata":{}},{"cell_type":"markdown","source":"***\n***Так как исходная модель была обучена на изображениях с аугментацией, то применим к тестовой выборке такую же аугментацию n раз. В результате усредним значения вероятностей.***\n***","metadata":{}},{"cell_type":"code","source":"p = 0.5 #Вероятность изменить изображение\n#Создание аугментатора\naugment = alb.Compose([\n    #Замена каналов в RGB палитре\n    alb.ChannelShuffle(p=p),\n    #Размытие изображения\n    alb.GaussianBlur(p=p),\n    #Добавление шума\n    alb.GaussNoise(p=p),\n    #Поворот вокруг вертикальной оси\n    alb.HorizontalFlip(p=p),\n    #Изменение оттенка и насыщенности\n    alb.HueSaturationValue(p=p),\n    #Изменение яркости\n    alb.RandomBrightness(p=p,limit=(0.2,0.4)),\n    #Изменение контраста\n    alb.RandomContrast(p=p,limit=(0.1,0.3)),\n    #Сдвиг в RGB палитре\n    alb.RGBShift(p=p),\n    #Вращение изображения\n    alb.ShiftScaleRotate(shift_limit=0.0625,      #Коэффициент изменения сдвига\n                         scale_limit=(0.1,0.2),   #Коэффициент изменение масштаба\n                         interpolation=1,         #Флаг для вида интерполяции (линейная)\n                         border_mode=4,           #Флаг для экстраполяцц (отражение)\n                         rotate_limit=20,         #Угол поворота\n                         p=0.7),                  #Вероятность\n    #Изменение размера на заданный\n    alb.Resize(IMG_SIZE, IMG_SIZE)\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Генерируем данные заного\n#Генератор для обучающей и валидационной выборок\ntest_gen =  ImageDataAugmentor(rescale=1.0/255,                     #Масштабирование\n                               augment=augment,                     #Аугментатор\n                               seed=RANDOM_SEED,                    #Для воспроизведения\n                               validation_split=VAL_SPLIT)          #Размер выборки\n#Создание тестовой выборки\ntest_sub_generator = test_gen.\\\n            flow_from_dataframe(dataframe=sample_submission,\n                                x_col=\"Id\",\n                                y_col=None,\n                                directory=PATH+'test_upload/',\n                                class_mode=None,\n                                batch_size=BATCH_SIZE,\n                                shuffle=False,\n                                target_size=(IMG_SIZE, IMG_SIZE),\n                                seed=RANDOM_SEED)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n***Количество изменений было подобрано опытным путем. Значения 10-12 являются оптимальными. Больше не дает существенного прироста, а меньше уменьшают значение метрики.***\n***","metadata":{}},{"cell_type":"code","source":"#Количество изменений\nn_tta = 12\n#Массив для сохранений\npredictions = []\n#Перебор\nfor i in range(n_tta):\n    print('{} / {}'.format(1+i, i))\n    preds = model.predict(test_sub_generator, verbose=1) \n    predictions.append(preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n***TTA позволил улучшить результат на ~0.2%.***\n***","metadata":{}},{"cell_type":"markdown","source":"# 10. Kaggle v.2","metadata":{}},{"cell_type":"markdown","source":"***\n***Результат на Kaggle приведен в конце notebook.***\n***","metadata":{}},{"cell_type":"code","source":"#Взятие среднего\npred = np.mean(predictions, axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Функция для вывода на Kaggle TTA\ndef to_Kaggle_TTA(predictions):\n    predictions = np.argmax(predictions, axis=-1)\n    label_map = (train_datagen.class_indices)\n    label_map = dict((v,k) for k,v in label_map.items())\n    predictions = [label_map[k] for k in predictions]\n    filenames_with_dir=test_sub_generator.filenames\n    submission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\n    submission['Id'] = submission['Id'].replace('test_upload/','')\n    submission.to_csv('submission_TTA.csv', index=False)\n    print('Save submit')\n    pass","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#submit на Kaggle\nto_Kaggle_TTA(pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n# Вывод\n***","metadata":{}},{"cell_type":"code","source":"#Kaggle\n#0.97453 - B5 + 16 + relu + TTA\n#0.97438 - B5 + 16 + relu\n#0.97348 - B5 + 32 + elu + TTA","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}